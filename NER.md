### Сложности в задаче NER:
1. Самое главное - разметка. Если ее достаточно (обычно от 200-500 примеров), модель может хорошо обучиться. При этом на первых этапах разметки всегда важно делать кросс-разметку и оценивать ее согласованность. На основе несостыковок вносятяся изменения в инструкцию для разметки, изменения обсуждаются с разметчиками и происходит переход к следующему циклу разметки.
2. Чем проще сущности - тем лучше. Если даже разметчик сильно сомневается, к какому типу сущности отнести данный случай, модели будет еще сложнее. Необходимо максимально разграничить классы, насколько это возможно.
3. Встречаются случаи, когда одно слово является частью двух разных сущностей, например, "Bank of China" является сущностью типа ORG, при этом слово China относится также к сущностям типа LOC. Задачу выделения таких сущностей называют Nested NER. К ней есть множество подходов, но самое простое из решений - использование Multilabel подхода, когда каждый токен может быть отнесен к любому количеству типов сущностей.
4. 

### Few shot NER
Отдельной областью исследований является изучение подходов к решению задачи Few shot NER, когда для выделения определенного типа сущностей достаточно несколько обучающих примеров (до 100)
Одно из направлений - решение этой задачи как задачи QA (question answering).
Есть 2 направления: Extractive QA и Generative QA.

QaNER: Prompting Question Answering Models for Few-shot Named Entity Recognition (https://arxiv.org/pdf/2203.01543.pdf)
Реализация: https://github.com/dayyass/QaNER
+ хорош для few shot
+ решает задачу nested NER, так как запросы разделены
- на больших данных обычный подход обгоняет qaNER
- помимо обучения на разметке необходимо предобучить на squad
- сложность - O(m), m - количество типов сущностей
- есть сложности с обработкой предиктов/разметки, когда одна сущность может встречаться несколько раз в тексте

Как обучить? 
Обучаем Берт на squad
Преобразуем датасет в нужный promt-context-labels формат
Обучаем на разметке token classification
Постпроцессим сущности
